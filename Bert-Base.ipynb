{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbcd83d4-149b-4e2c-8d54-54a3b4dfca97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abec9f30-fbf6-4819-82f3-39e99121fe56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b0ec48-1e0c-45fd-b50f-693174a15db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27534010-d881-4e37-b1a1-54f7e60e77f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!mkdir squad\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f53781-09a5-4b70-ad07-d23710f94d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path to the SQuAD 2.0 training data\n",
    "path = \"squad/train-v2.0.json\"\n",
    "\n",
    "# Load and preprocess the SQuAD 2.0 data\n",
    "def load_squad_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "        \n",
    "    texts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    texts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return texts, questions, answers\n",
    "\n",
    "# Preprocess the data to find answer start and end positions\n",
    "train_texts, train_queries, train_answers = load_squad_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0ce6b8-12aa-4112-83ef-f32a5146ba59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give the path for SQuAD 2.0 validation data\n",
    "path = Path('squad/dev-v2.0.json')\n",
    "\n",
    "# Load and preprocess the SQuAD 2.0 data\n",
    "def load_squad_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    texts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    texts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return texts, questions, answers\n",
    "\n",
    "# Preprocess the data to find answer start and end positions\n",
    "val_texts, val_queries, val_answers = load_squad_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77661fda-32db-4a42-87fd-066c3909bbba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86821\n",
      "86821\n",
      "86821\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))\n",
    "print(len(train_queries))\n",
    "print(len(train_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c78e9a41-7f67-41e0-baa0-b3f5ca02d6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20302\n",
      "20302\n",
      "20302\n"
     ]
    }
   ],
   "source": [
    "print(len(val_texts))\n",
    "print(len(val_queries))\n",
    "print(len(val_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc58784-7b55-4a23-8351-d18b0a8a927e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for answer, text in zip(train_answers, train_texts):\n",
    "    real_answer = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    # Get the real end index\n",
    "    end_idx = start_idx + len(real_answer)\n",
    "\n",
    "    # Deal with the problem of 1 or 2 more characters\n",
    "    if text[start_idx:end_idx] == real_answer:\n",
    "        answer['answer_end'] = end_idx\n",
    "    # When the real answer is more by one character\n",
    "    elif text[start_idx-1:end_idx-1] == real_answer:\n",
    "        answer['answer_start'] = start_idx - 1\n",
    "        answer['answer_end'] = end_idx - 1\n",
    "    # When the real answer is more by two characters\n",
    "    elif text[start_idx-2:end_idx-2] == real_answer:\n",
    "        answer['answer_start'] = start_idx - 2\n",
    "        answer['answer_end'] = end_idx - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e10952-c3e5-4d3b-98f1-4cd5c4ae4d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for answer, text in zip(val_answers, val_texts):\n",
    "    real_answer = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    # Get the real end index\n",
    "    end_idx = start_idx + len(real_answer)\n",
    "\n",
    "    # Deal with the problem of 1 or 2 more characters\n",
    "    if text[start_idx:end_idx] == real_answer:\n",
    "        answer['answer_end'] = end_idx\n",
    "    # When the real answer is more by one character\n",
    "    elif text[start_idx-1:end_idx-1] == real_answer:\n",
    "        answer['answer_start'] = start_idx - 1\n",
    "        answer['answer_end'] = end_idx - 1\n",
    "    # When the real answer is more by two characters\n",
    "    elif text[start_idx-2:end_idx-2] == real_answer:\n",
    "        answer['answer_start'] = start_idx - 2\n",
    "        answer['answer_end'] = end_idx - 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289a1edb-9530-4893-894d-d1e4287958d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38db2dbf-7149-4c2a-8f6c-afd0be83f313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, train_queries, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, val_queries, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fabfc17f-77ee-4990-a3e9-419740eb2162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "        \n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "            \n",
    "        # if end position is None, the 'char_to_token' function points to the space after the correct token, so add - 1\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - 1)\n",
    "            \n",
    "            # if end position is still None the answer passage has been truncated\n",
    "            if end_positions[-1] is None:\n",
    "                count += 1\n",
    "                end_positions[-1] = tokenizer.model_max_length\n",
    "    print(count)\n",
    "    \n",
    "    # Update the data in dictionary\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036241c0-c91f-43bd-ae3e-4fe540370c14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa551276-84c4-4e0d-8fbf-48a1cfa813fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afbe90c5-db86-4d0a-800e-2c54219d1110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43959391-83e4-4518-ac83-109c453cfcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "958da0f6-1882-4888-b6fe-ed6c9d74b1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available()\n",
    "                      else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e3b01ce-adfd-47a4-9e37-221875ee22f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-base-cased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5be7752e-88da-4d2c-9f28-a4c23c9d097e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa.ekbote/.local/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d8fffa-44c6-4086-9705-7c940e3aeb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    \n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    \n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "    \n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return normalize_answer(prediction) == normalize_answer(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "125add30-726e-4d30-96a1-d448ef8dcb03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, epochs, model_save_path):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    print_every = 1000  # Print every 500 steps\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler for mixed precision training\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_train_exact_match = 0\n",
    "        total_train_f1 = 0\n",
    "        total_train_examples = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            with autocast():  # Enable automatic mixed precision\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # Backward pass with mixed precision\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Convert logits to answer spans (this part is not affected by mixed precision)\n",
    "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "            start_predictions = torch.argmax(start_logits, dim=-1)\n",
    "            end_predictions = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "            for i in range(input_ids.size(0)):\n",
    "                start_pred = start_predictions[i].item()\n",
    "                end_pred = end_predictions[i].item()\n",
    "                predicted_answer = tokenizer.decode(input_ids[i, start_pred:end_pred + 1])\n",
    "\n",
    "                ground_truth_answer = tokenizer.decode(input_ids[i, start_positions[i]:end_positions[i] + 1])\n",
    "\n",
    "                total_train_exact_match += exact_match_score(predicted_answer, ground_truth_answer)\n",
    "                total_train_f1 += f1_score(predicted_answer, ground_truth_answer)\n",
    "                total_train_examples += 1\n",
    "\n",
    "            if (batch_idx + 1) % print_every == 0:\n",
    "                print(f\"Train Epoch: {epoch + 1} [{batch_idx + 1}/{len(train_loader)}]\\tLoss: {loss.item():.6f}\\tExact Match: {total_train_exact_match / total_train_examples:.4f}\\tF1: {total_train_f1 / total_train_examples:.4f}\")\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_exact_match = total_train_exact_match / total_train_examples\n",
    "        avg_train_f1 = total_train_f1 / total_train_examples\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append((avg_train_exact_match, avg_train_f1))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_exact_match = 0\n",
    "        total_val_f1 = 0\n",
    "        total_val_examples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                start_positions = batch['start_positions'].to(device)\n",
    "                end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "                with autocast():  # Enable automatic mixed precision for evaluation\n",
    "                    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "                    loss = outputs.loss\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # Convert logits to answer spans (this part is not affected by mixed precision)\n",
    "                start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "                start_predictions = torch.argmax(start_logits, dim=-1)\n",
    "                end_predictions = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "                for i in range(input_ids.size(0)):\n",
    "                    start_pred = start_predictions[i].item()\n",
    "                    end_pred = end_predictions[i].item()\n",
    "                    predicted_answer = tokenizer.decode(input_ids[i, start_pred:end_pred + 1])\n",
    "\n",
    "                    ground_truth_answer = tokenizer.decode(input_ids[i, start_positions[i]:end_positions[i] + 1])\n",
    "\n",
    "                    total_val_exact_match += exact_match_score(predicted_answer, ground_truth_answer)\n",
    "                    total_val_f1 += f1_score(predicted_answer, ground_truth_answer)\n",
    "                    total_val_examples += 1\n",
    "\n",
    "                if (batch_idx + 1) % print_every == 0:\n",
    "                    print(f\"Val Epoch: {epoch + 1} [{batch_idx + 1}/{len(val_loader)}]\\tLoss: {loss.item():.6f}\\tExact Match: {total_val_exact_match / total_val_examples:.4f}\\tF1: {total_val_f1 / total_val_examples:.4f}\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_exact_match = total_val_exact_match / total_val_examples\n",
    "        avg_val_f1 = total_val_f1 / total_val_examples\n",
    "\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append((avg_val_exact_match, avg_val_f1))\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}:')\n",
    "        print(f'Train Loss: {avg_train_loss:.4f}, Train Exact Match: {avg_train_exact_match:.4f}, Train F1: {avg_train_f1:.4f}')\n",
    "        print(f'Val Loss: {avg_val_loss:.4f}, Val Exact Match: {avg_val_exact_match:.4f}, Val F1: {avg_val_f1:.4f}')\n",
    "\n",
    "        # Save the model after each epoch\n",
    "        torch.save(model.state_dict(), f\"{model_save_path}/model_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11a5a6e-910e-471a-8833-fd390878e188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/10853]\tLoss: 2.505325\tExact Match: 0.3407\tF1: 0.4618\n",
      "Train Epoch: 1 [2000/10853]\tLoss: 1.322605\tExact Match: 0.4218\tF1: 0.5527\n",
      "Train Epoch: 1 [3000/10853]\tLoss: 0.945814\tExact Match: 0.4588\tF1: 0.5938\n",
      "Train Epoch: 1 [4000/10853]\tLoss: 0.816831\tExact Match: 0.4818\tF1: 0.6186\n",
      "Train Epoch: 1 [5000/10853]\tLoss: 1.080849\tExact Match: 0.4969\tF1: 0.6351\n",
      "Train Epoch: 1 [6000/10853]\tLoss: 1.007084\tExact Match: 0.5059\tF1: 0.6451\n",
      "Train Epoch: 1 [7000/10853]\tLoss: 0.526085\tExact Match: 0.5144\tF1: 0.6536\n",
      "Train Epoch: 1 [8000/10853]\tLoss: 0.571599\tExact Match: 0.5215\tF1: 0.6606\n",
      "Train Epoch: 1 [9000/10853]\tLoss: 1.702614\tExact Match: 0.5271\tF1: 0.6665\n",
      "Train Epoch: 1 [10000/10853]\tLoss: 0.677151\tExact Match: 0.5326\tF1: 0.6724\n",
      "Val Epoch: 1 [1000/2538]\tLoss: 1.196064\tExact Match: 0.5795\tF1: 0.7306\n",
      "Val Epoch: 1 [2000/2538]\tLoss: 0.826177\tExact Match: 0.5787\tF1: 0.7300\n",
      "Epoch 1/3:\n",
      "Train Loss: 1.3712, Train Exact Match: 0.5365, Train F1: 0.6764\n",
      "Val Loss: 1.2536, Val Exact Match: 0.5795, Val F1: 0.7305\n",
      "Train Epoch: 2 [1000/10853]\tLoss: 0.999150\tExact Match: 0.6683\tF1: 0.7992\n",
      "Train Epoch: 2 [2000/10853]\tLoss: 1.496332\tExact Match: 0.6604\tF1: 0.7915\n",
      "Train Epoch: 2 [3000/10853]\tLoss: 1.041807\tExact Match: 0.6558\tF1: 0.7876\n",
      "Train Epoch: 2 [4000/10853]\tLoss: 1.135070\tExact Match: 0.6543\tF1: 0.7866\n",
      "Train Epoch: 2 [5000/10853]\tLoss: 0.738135\tExact Match: 0.6520\tF1: 0.7845\n",
      "Train Epoch: 2 [6000/10853]\tLoss: 0.805541\tExact Match: 0.6507\tF1: 0.7830\n",
      "Train Epoch: 2 [7000/10853]\tLoss: 1.954992\tExact Match: 0.6493\tF1: 0.7818\n",
      "Train Epoch: 2 [8000/10853]\tLoss: 0.858559\tExact Match: 0.6488\tF1: 0.7812\n",
      "Train Epoch: 2 [9000/10853]\tLoss: 0.980929\tExact Match: 0.6485\tF1: 0.7804\n",
      "Train Epoch: 2 [10000/10853]\tLoss: 1.177597\tExact Match: 0.6468\tF1: 0.7793\n",
      "Val Epoch: 2 [1000/2538]\tLoss: 1.006567\tExact Match: 0.5895\tF1: 0.7352\n",
      "Val Epoch: 2 [2000/2538]\tLoss: 1.681076\tExact Match: 0.5881\tF1: 0.7343\n",
      "Epoch 2/3:\n",
      "Train Loss: 0.9627, Train Exact Match: 0.6455, Train F1: 0.7781\n",
      "Val Loss: 1.2601, Val Exact Match: 0.5869, Val F1: 0.7325\n",
      "Train Epoch: 3 [1000/10853]\tLoss: 0.552908\tExact Match: 0.7097\tF1: 0.8287\n",
      "Train Epoch: 3 [2000/10853]\tLoss: 0.686409\tExact Match: 0.7083\tF1: 0.8293\n",
      "Train Epoch: 3 [3000/10853]\tLoss: 0.233452\tExact Match: 0.7041\tF1: 0.8271\n",
      "Train Epoch: 3 [4000/10853]\tLoss: 2.017475\tExact Match: 0.7022\tF1: 0.8247\n",
      "Train Epoch: 3 [5000/10853]\tLoss: 0.562286\tExact Match: 0.7020\tF1: 0.8246\n",
      "Train Epoch: 3 [6000/10853]\tLoss: 1.234741\tExact Match: 0.7001\tF1: 0.8231\n",
      "Train Epoch: 3 [7000/10853]\tLoss: 0.924424\tExact Match: 0.6999\tF1: 0.8227\n",
      "Train Epoch: 3 [8000/10853]\tLoss: 0.649054\tExact Match: 0.6992\tF1: 0.8220\n",
      "Train Epoch: 3 [9000/10853]\tLoss: 1.491345\tExact Match: 0.6982\tF1: 0.8208\n",
      "Train Epoch: 3 [10000/10853]\tLoss: 1.066063\tExact Match: 0.6955\tF1: 0.8187\n",
      "Val Epoch: 3 [1000/2538]\tLoss: 0.349110\tExact Match: 0.5861\tF1: 0.7357\n",
      "Val Epoch: 3 [2000/2538]\tLoss: 2.086790\tExact Match: 0.5814\tF1: 0.7321\n",
      "Epoch 3/3:\n",
      "Train Loss: 0.7847, Train Exact Match: 0.6949, Train F1: 0.8181\n",
      "Val Loss: 1.3074, Val Exact Match: 0.5805, Val F1: 0.7315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "model_save_path = \"/home/sa.ekbote/cai6307-parsingpandas/bert_squad_v2/\"\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train_and_evaluate(model, train_loader, val_loader, optim, epochs, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc05fd9c-50c1-42f2-a54a-0457bb35191d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming train_losses and val_losses are populated from the train_and_evaluate function\n",
    "plot_losses(train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd3d1fb0-682a-4acf-ac62-e8be27562f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracies(train_accuracies, val_accuracies, metric_name):\n",
    "    epochs = range(1, len(train_accuracies) + 1)\n",
    "    train_scores = [score[0] if metric_name == 'EM' else score[1] for score in train_accuracies]\n",
    "    val_scores = [score[0] if metric_name == 'EM' else score[1] for score in val_accuracies]\n",
    "\n",
    "    plt.plot(epochs, train_scores, 'bo-', label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, val_scores, 'ro-', label=f'Validation {metric_name}')\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming train_accuracies and val_accuracies are populated from the train_and_evaluate function\n",
    "plot_accuracies(train_accuracies, val_accuracies, 'EM')  # Plot for Exact Match\n",
    "plot_accuracies(train_accuracies, val_accuracies, 'F1')  # Plot for F1 Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6506feda-6776-42f4-a3f5-d6e3e0bde4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model to Google Drive\n",
    "torch.save(model, '/home/sa.ekbote/cai6307-parsingpandas/models/bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "697ebf02-21a9-4594-a7fe-9153609cab3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model2 = torch.load('/home/sa.ekbote/cai6307-parsingpandas/models/bert-base-cased',map_location=torch.device('cpu'))\n",
    "bert_model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac0c6259-de9c-4c3a-8dcc-d1aa944d103d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(context,query):\n",
    "    \n",
    "    inputs = tokenizer.encode_plus(query, context, return_tensors='pt')\n",
    "    outputs = bert_model2(**inputs)\n",
    "    answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(outputs[1]) + 1 \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "    return answer\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "    \n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "    \n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "    \n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deee7620-ead2-4169-99fa-eaa1458dd673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def give_an_answer(context,query,answer):\n",
    "    prediction = predict(context,query)\n",
    "    em_score = compute_exact_match(prediction, answer)\n",
    "    f1_score = compute_f1(prediction, answer)\n",
    "    print(f\"Question: {query}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "    print(f\"EM: {em_score}\")\n",
    "    print(f\"F1: {f1_score}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d922dd6b-3bc7-4e0e-926e-f953c64a2bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How old is Alexa?\n",
      "Prediction: 21 years old.\n",
      "True Answer: 21\n",
      "EM: 0\n",
      "F1: 0.5\n",
      "\n",
      "\n",
      "Question: Where does Alexa live now?\n",
      "Prediction: Peristeri of Athens,\n",
      "True Answer: Kaisariani of Athens\n",
      "EM: 0\n",
      "F1: 0.6666666666666666\n",
      "\n",
      "\n",
      "Question: Where Alexa used to live?\n",
      "Prediction: Peristeri of Athens,\n",
      "True Answer: Peristeri of Athens\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def is_answerable(context, answer):\n",
    "    # Normalize both the context and the answer\n",
    "    normalized_context = normalize_text(context)\n",
    "    normalized_answer = normalize_text(answer)\n",
    "    \n",
    "    # Check if the normalized answer is in the normalized context\n",
    "    return normalized_answer in normalized_context\n",
    "\n",
    "# Now let's filter out the unanswerable questions\n",
    "context = \"Hi! My name is Alexa and I am 21 years old. I used to live in Peristeri of Athens, but now I moved on in Kaisariani of Athens.\"\n",
    "\n",
    "queries = [\n",
    "    \"How old is Alexa?\",\n",
    "    \"Where does Alexa live now?\",\n",
    "    \"Where Alexa used to live?\",\n",
    "    \"What is the capital of France?\"  # This question is unanswerable based on the context provided\n",
    "]\n",
    "\n",
    "answers = [\n",
    "    \"21\",\n",
    "    \"Kaisariani of Athens\",\n",
    "    \"Peristeri of Athens\",\n",
    "    \"Paris\"  # This answer is not present in the context, so the question is unanswerable\n",
    "]\n",
    "\n",
    "# Using a list comprehension to filter only answerable questions based on the context\n",
    "answerable_pairs = [(q, a) for q, a in zip(queries, answers) if is_answerable(context, a)]\n",
    "\n",
    "# Process only answerable questions\n",
    "for q, a in answerable_pairs:\n",
    "    give_an_answer(context, q, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e877b70a-1fa3-4289-ad80-83b61229d7db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When did Queen found?\n",
      "Prediction: 1970.\n",
      "True Answer: 1970\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n",
      "Question: Who were the basic members of Queen band?\n",
      "Prediction: Freddie Mercury ( lead vocals, piano ), Brian May ( guitar, vocals ), Roger Taylor ( drums, vocals ) and John Deacon ( bass ).\n",
      "True Answer: Freddie Mercury, Brian May, Roger Taylor and John Deacon\n",
      "EM: 0\n",
      "F1: 0.6923076923076924\n",
      "\n",
      "\n",
      "Question: What kind of band they are?\n",
      "Prediction: British rock\n",
      "True Answer: rock\n",
      "EM: 0\n",
      "F1: 0.6666666666666666\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\" Queen are a British rock band formed in London in 1970. Their classic line-up was Freddie Mercury (lead vocals, piano), \n",
    "            Brian May (guitar, vocals), Roger Taylor (drums, vocals) and John Deacon (bass). Their earliest works were influenced \n",
    "            by progressive rock, hard rock and heavy metal, but the band gradually ventured into more conventional and radio-friendly \n",
    "            works by incorporating further styles, such as arena rock and pop rock. \"\"\"\n",
    "\n",
    "queries = [\"When did Queen found?\",\n",
    "           \"Who were the basic members of Queen band?\",\n",
    "           \"What kind of band they are?\"\n",
    "          ]\n",
    "answers = [\"1970\",\n",
    "           \"Freddie Mercury, Brian May, Roger Taylor and John Deacon\",\n",
    "           \"rock\"\n",
    "          ]\n",
    "\n",
    "for q,a in zip(queries,answers):\n",
    "    give_an_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dda900d1-efd0-42aa-80c2-74a3a574d1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many metres is Olympus?\n",
      "Prediction: 2917\n",
      "True Answer: 2917\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n",
      "Question: Where Olympus is near?\n",
      "Prediction: the Gulf of Thérmai of the Aegean Sea,\n",
      "True Answer: Gulf of Thérmai of the Aegean Sea\n",
      "EM: 1\n",
      "F1: 0.8333333333333334\n",
      "\n",
      "\n",
      "Question: How far away is Olympus from Thessaloniki?\n",
      "Prediction: 80 km ( 50 mi )\n",
      "True Answer: 80 km (50 mi)\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\" Mount Olympus is the highest mountain in Greece. It is part of the Olympus massif near \n",
    "              the Gulf of Thérmai of the Aegean Sea, located in the Olympus Range on the border between \n",
    "              Thessaly and Macedonia, between the regional units of Pieria and Larissa, about 80 km (50 mi) \n",
    "              southwest from Thessaloniki. Mount Olympus has 52 peaks and deep gorges. The highest peak, \n",
    "              Mytikas, meaning \"nose\", rises to 2917 metres (9,570 ft). \"\"\"\n",
    "\n",
    "queries = [\n",
    "           \"How many metres is Olympus?\",\n",
    "           \"Where Olympus is near?\",\n",
    "           \"How far away is Olympus from Thessaloniki?\"\n",
    "          ]\n",
    "answers = [\n",
    "           \"2917\",\n",
    "           \"Gulf of Thérmai of the Aegean Sea\",\n",
    "           \"80 km (50 mi)\"\n",
    "          ]\n",
    "\n",
    "for q,a in zip(queries,answers):\n",
    "    give_an_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91fcdb72-c287-4cbc-8aa6-1db5cd39ae9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is COVID-19?\n",
      "Prediction: \n",
      "True Answer: an ongoing pandemic of coronavirus disease 2019\n",
      "EM: 0\n",
      "F1: 0\n",
      "\n",
      "\n",
      "Question: What is caused by COVID-19?\n",
      "Prediction: \n",
      "True Answer: severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\n",
      "EM: 0\n",
      "F1: 0\n",
      "\n",
      "\n",
      "Question: How many cases have been confirmed from COVID-19?\n",
      "Prediction: 2. 3 million\n",
      "True Answer: more than 105 million cases\n",
      "EM: 0\n",
      "F1: 0.25\n",
      "\n",
      "\n",
      "Question: How many deaths have been confirmed from COVID-19?\n",
      "Prediction: 2. 3 million\n",
      "True Answer: more than 2.3 million deaths\n",
      "EM: 0\n",
      "F1: 0.25\n",
      "\n",
      "\n",
      "Question: How is COVID-19 spread?\n",
      "Prediction: through the air when people are near each other.\n",
      "True Answer: mainly through the air when people are near each other. It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. It may also spread via contaminated surfaces.\n",
      "EM: 0\n",
      "F1: 0.35555555555555557\n",
      "\n",
      "\n",
      "Question: How long can an infected person remain infected?\n",
      "Prediction: up to two weeks,\n",
      "True Answer: up to two weeks\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n",
      "Question: Can a infected person spread the virus even if they don't have symptoms?\n",
      "Prediction: \n",
      "True Answer: yes\n",
      "EM: 0\n",
      "F1: 0\n",
      "\n",
      "\n",
      "Question: What do elephants eat?\n",
      "Prediction: \n",
      "True Answer:  \n",
      "EM: 1\n",
      "F1: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\" The COVID-19 pandemic, also known as the coronavirus pandemic, is an ongoing pandemic of coronavirus disease 2019 (COVID-19) \n",
    "              caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It was first identified in December 2019 in Wuhan, China. \n",
    "              The World Health Organization declared the outbreak a Public Health Emergency of International Concern in January 2020 and a pandemic \n",
    "              in March 2020. As of 6 February 2021, more than 105 million cases have been confirmed, with more than 2.3 million deaths attributed to COVID-19.\n",
    "              Symptoms of COVID-19 are highly variable, ranging from none to severe illness. The virus spreads mainly through the air when people are \n",
    "              near each other.[b] It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. \n",
    "              It may also spread via contaminated surfaces. People remain infectious for up to two weeks, and can spread the virus even if they do not show symptoms.[9]\"\"\"\n",
    "\n",
    "queries = [\n",
    "           \"What is COVID-19?\",\n",
    "           \"What is caused by COVID-19?\",\n",
    "           \"How many cases have been confirmed from COVID-19?\",\n",
    "           \"How many deaths have been confirmed from COVID-19?\",\n",
    "           \"How is COVID-19 spread?\",\n",
    "           \"How long can an infected person remain infected?\",\n",
    "           \"Can a infected person spread the virus even if they don't have symptoms?\",\n",
    "           \"What do elephants eat?\"\n",
    "          ]\n",
    "answers = [\n",
    "           \"an ongoing pandemic of coronavirus disease 2019\",\n",
    "           \"severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\",\n",
    "           \"more than 105 million cases\",\n",
    "           \"more than 2.3 million deaths\",\n",
    "           \"mainly through the air when people are near each other. It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. It may also spread via contaminated surfaces.\",\n",
    "           \"up to two weeks\",\n",
    "           \"yes\",\n",
    "           \" \"\n",
    "          ]\n",
    "\n",
    "for q,a in zip(queries,answers):\n",
    "      give_an_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6372a875-ec7e-49b4-9cc9-9854fee29fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who wrote Harry Potter's novels?\n",
      "Prediction: J. K. Rowling.\n",
      "True Answer: J. K. Rowling\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n",
      "Question: Who are Harry Potter's friends?\n",
      "Prediction: Hermione Granger and Ron Weasley,\n",
      "True Answer: Hermione Granger and Ron Weasley\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n",
      "Question: Who is the enemy of Harry Potter?\n",
      "Prediction: Harry Potter? [SEP] Harry Potter is a series of seven fantasy novels written by British author, J. K. Rowling. The novels chronicle the lives of a young wizard,\n",
      "True Answer: Lord Voldemort\n",
      "EM: 0\n",
      "F1: 0\n",
      "\n",
      "\n",
      "Question: What are Muggles?\n",
      "Prediction: non - magical people )\n",
      "True Answer: non-magical people\n",
      "EM: 0\n",
      "F1: 0.4\n",
      "\n",
      "\n",
      "Question: Which is the name of Harry Poter's first novel?\n",
      "Prediction: Harry Potter and the Philosopher ' s Stone,\n",
      "True Answer: Harry Potter and the Philosopher's Stone\n",
      "EM: 0\n",
      "F1: 0.7272727272727272\n",
      "\n",
      "\n",
      "Question: When did the first novel release?\n",
      "Prediction: 26 June 1997,\n",
      "True Answer: 26 June 1997\n",
      "EM: 1\n",
      "F1: 1.0\n",
      "\n",
      "\n",
      "Question: Who was attracted by Harry Potter novels?\n",
      "Prediction: Hermione Granger and Ron Weasley,\n",
      "True Answer: a wide adult audience as well as younger readers\n",
      "EM: 0\n",
      "F1: 0\n",
      "\n",
      "\n",
      "Question: How many languages Harry Potter has been translated into? \n",
      "Prediction: seven\n",
      "True Answer: eighty\n",
      "EM: 0\n",
      "F1: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\" Harry Potter is a series of seven fantasy novels written by British author, J. K. Rowling. The novels chronicle the lives of a young wizard, \n",
    "              Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and Wizardry. \n",
    "              The main story arc concerns Harry's struggle against Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard \n",
    "              governing body known as the Ministry of Magic and subjugate all wizards and Muggles (non-magical people). Since the release of the first novel, \n",
    "              Harry Potter and the Philosopher's Stone, on 26 June 1997, the books have found immense popularity, positive reviews, and commercial success worldwide. \n",
    "              They have attracted a wide adult audience as well as younger readers and are often considered cornerstones of modern young adult literature.[2] \n",
    "              As of February 2018, the books have sold more than 500 million copies worldwide, making them the best-selling book series in history, and have been translated \n",
    "              into eighty languages.[3] The last four books consecutively set records as the fastest-selling books in history, with the final installment selling roughly \n",
    "              eleven million copies in the United States within twenty-four hours of its release.  \"\"\"\n",
    "\n",
    "queries = [\n",
    "           \"Who wrote Harry Potter's novels?\",\n",
    "           \"Who are Harry Potter's friends?\",\n",
    "           \"Who is the enemy of Harry Potter?\",\n",
    "           \"What are Muggles?\",\n",
    "           \"Which is the name of Harry Poter's first novel?\",\n",
    "           \"When did the first novel release?\",\n",
    "           \"Who was attracted by Harry Potter novels?\",\n",
    "           \"How many languages Harry Potter has been translated into? \"\n",
    "          ]\n",
    "answers = [\n",
    "           \"J. K. Rowling\",\n",
    "           \"Hermione Granger and Ron Weasley\",\n",
    "           \"Lord Voldemort\",\n",
    "           \"non-magical people\",\n",
    "           \"Harry Potter and the Philosopher's Stone\",\n",
    "           \"26 June 1997\",\n",
    "           \"a wide adult audience as well as younger readers\",\n",
    "           \"eighty\"\n",
    "          ]\n",
    "\n",
    "for q,a in zip(queries,answers):\n",
    "      give_an_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2baa3c83-443f-402d-a24b-72c050dc5166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -idgetsnbextension (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ryptography (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yopenssl (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: colorlog in /apps/python/3.10/lib/python3.10/site-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: numpy in /apps/python/3.10/lib/python3.10/site-packages (from optuna) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/python/3.10/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /apps/python/3.10/lib/python3.10/site-packages (from optuna) (1.3.24)\n",
      "Requirement already satisfied: tqdm in /apps/python/3.10/lib/python3.10/site-packages (from optuna) (4.66.2)\n",
      "Requirement already satisfied: PyYAML in /apps/python/3.10/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /apps/python/3.10/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4 in /apps/python/3.10/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /apps/python/3.10/lib/python3.10/site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /apps/python/3.10/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -idgetsnbextension (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ryptography (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yopenssl (/apps/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: autogenes 1.0.4 has a non-standard dependency specifier matplotlib>=3.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of autogenes or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: alembic, optuna\n",
      "Successfully installed alembic-1.13.1 optuna-3.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a68aeff-3eef-4597-bbf5-32f9b2615fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 16:45:24,268] A new study created in memory with name: no-name-64470793-1358-46de-b310-d6e14beabd15\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/10853]\tLoss: 1.246460\tExact Match: 0.3430\tF1: 0.4652\n",
      "Train Epoch: 1 [2000/10853]\tLoss: 1.476093\tExact Match: 0.4181\tF1: 0.5513\n",
      "Train Epoch: 1 [3000/10853]\tLoss: 1.423202\tExact Match: 0.4567\tF1: 0.5917\n",
      "Train Epoch: 1 [4000/10853]\tLoss: 1.414765\tExact Match: 0.4769\tF1: 0.6139\n",
      "Train Epoch: 1 [5000/10853]\tLoss: 1.793976\tExact Match: 0.4904\tF1: 0.6285\n",
      "Train Epoch: 1 [6000/10853]\tLoss: 0.584310\tExact Match: 0.5029\tF1: 0.6412\n",
      "Train Epoch: 1 [7000/10853]\tLoss: 1.085196\tExact Match: 0.5120\tF1: 0.6505\n",
      "Train Epoch: 1 [8000/10853]\tLoss: 1.141405\tExact Match: 0.5197\tF1: 0.6579\n",
      "Train Epoch: 1 [9000/10853]\tLoss: 1.347730\tExact Match: 0.5260\tF1: 0.6645\n",
      "Train Epoch: 1 [10000/10853]\tLoss: 2.219108\tExact Match: 0.5319\tF1: 0.6703\n",
      "Val Epoch: 1 [1000/2538]\tLoss: 0.942244\tExact Match: 0.5823\tF1: 0.7244\n",
      "Val Epoch: 1 [2000/2538]\tLoss: 1.180310\tExact Match: 0.5876\tF1: 0.7297\n",
      "Epoch 1/3:\n",
      "Train Loss: 1.3722, Train Exact Match: 0.5357, Train F1: 0.6743\n",
      "Val Loss: 1.2124, Val Exact Match: 0.5859, Val F1: 0.7284\n",
      "Train Epoch: 2 [1000/10853]\tLoss: 0.307559\tExact Match: 0.6670\tF1: 0.7933\n",
      "Train Epoch: 2 [2000/10853]\tLoss: 0.823198\tExact Match: 0.6634\tF1: 0.7899\n",
      "Train Epoch: 2 [3000/10853]\tLoss: 2.038009\tExact Match: 0.6596\tF1: 0.7865\n",
      "Train Epoch: 2 [4000/10853]\tLoss: 0.702670\tExact Match: 0.6535\tF1: 0.7827\n",
      "Train Epoch: 2 [5000/10853]\tLoss: 2.277924\tExact Match: 0.6494\tF1: 0.7793\n",
      "Train Epoch: 2 [6000/10853]\tLoss: 1.717873\tExact Match: 0.6482\tF1: 0.7785\n",
      "Train Epoch: 2 [7000/10853]\tLoss: 1.024019\tExact Match: 0.6475\tF1: 0.7776\n",
      "Train Epoch: 2 [8000/10853]\tLoss: 2.241327\tExact Match: 0.6473\tF1: 0.7782\n",
      "Train Epoch: 2 [9000/10853]\tLoss: 1.121873\tExact Match: 0.6459\tF1: 0.7766\n",
      "Train Epoch: 2 [10000/10853]\tLoss: 2.941319\tExact Match: 0.6450\tF1: 0.7762\n",
      "Val Epoch: 2 [1000/2538]\tLoss: 1.818653\tExact Match: 0.6035\tF1: 0.7476\n",
      "Val Epoch: 2 [2000/2538]\tLoss: 0.820893\tExact Match: 0.5984\tF1: 0.7403\n",
      "Epoch 2/3:\n",
      "Train Loss: 0.9643, Train Exact Match: 0.6439, Train F1: 0.7758\n",
      "Val Loss: 1.2701, Val Exact Match: 0.5959, Val F1: 0.7393\n",
      "Train Epoch: 3 [1000/10853]\tLoss: 0.532433\tExact Match: 0.7130\tF1: 0.8337\n",
      "Train Epoch: 3 [2000/10853]\tLoss: 0.254153\tExact Match: 0.7041\tF1: 0.8264\n",
      "Train Epoch: 3 [3000/10853]\tLoss: 0.705674\tExact Match: 0.7043\tF1: 0.8265\n",
      "Train Epoch: 3 [4000/10853]\tLoss: 0.616520\tExact Match: 0.7014\tF1: 0.8245\n",
      "Train Epoch: 3 [5000/10853]\tLoss: 1.379412\tExact Match: 0.7002\tF1: 0.8219\n",
      "Train Epoch: 3 [6000/10853]\tLoss: 0.654078\tExact Match: 0.6986\tF1: 0.8209\n",
      "Train Epoch: 3 [7000/10853]\tLoss: 0.552443\tExact Match: 0.6985\tF1: 0.8209\n",
      "Train Epoch: 3 [8000/10853]\tLoss: 1.344168\tExact Match: 0.6969\tF1: 0.8199\n",
      "Train Epoch: 3 [9000/10853]\tLoss: 0.867638\tExact Match: 0.6954\tF1: 0.8184\n",
      "Train Epoch: 3 [10000/10853]\tLoss: 1.006831\tExact Match: 0.6928\tF1: 0.8164\n",
      "Val Epoch: 3 [1000/2538]\tLoss: 1.054220\tExact Match: 0.5851\tF1: 0.7349\n",
      "Val Epoch: 3 [2000/2538]\tLoss: 1.259261\tExact Match: 0.5885\tF1: 0.7379\n",
      "Epoch 3/3:\n",
      "Train Loss: 0.7884, Train Exact Match: 0.6913, Train F1: 0.8153\n",
      "Val Loss: 1.2344, Val Exact Match: 0.5902, Val F1: 0.7392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 17:21:48,874] Trial 0 finished with value: 0.7356135293883699 and parameters: {'num_attention_heads': 12}. Best is trial 0 with value: 0.7356135293883699.\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/10853]\tLoss: 3.968628\tExact Match: 0.0205\tF1: 0.0627\n",
      "Train Epoch: 1 [2000/10853]\tLoss: 3.304688\tExact Match: 0.0279\tF1: 0.0702\n",
      "Train Epoch: 1 [3000/10853]\tLoss: 3.548706\tExact Match: 0.0417\tF1: 0.0876\n",
      "Train Epoch: 1 [4000/10853]\tLoss: 3.689636\tExact Match: 0.0525\tF1: 0.1014\n",
      "Train Epoch: 1 [5000/10853]\tLoss: 3.615112\tExact Match: 0.0636\tF1: 0.1153\n",
      "Train Epoch: 1 [6000/10853]\tLoss: 3.655334\tExact Match: 0.0752\tF1: 0.1300\n",
      "Train Epoch: 1 [7000/10853]\tLoss: 4.132950\tExact Match: 0.0893\tF1: 0.1482\n",
      "Train Epoch: 1 [8000/10853]\tLoss: 2.382309\tExact Match: 0.1082\tF1: 0.1726\n",
      "Train Epoch: 1 [9000/10853]\tLoss: 1.703566\tExact Match: 0.1307\tF1: 0.2016\n",
      "Train Epoch: 1 [10000/10853]\tLoss: 2.493933\tExact Match: 0.1528\tF1: 0.2293\n",
      "Val Epoch: 1 [1000/2538]\tLoss: 2.105357\tExact Match: 0.4280\tF1: 0.5638\n",
      "Val Epoch: 1 [2000/2538]\tLoss: 1.974812\tExact Match: 0.4311\tF1: 0.5682\n",
      "Epoch 1/3:\n",
      "Train Loss: 2.8541, Train Exact Match: 0.1709, Train F1: 0.2517\n",
      "Val Loss: 1.7413, Val Exact Match: 0.4328, Val F1: 0.5695\n",
      "Train Epoch: 2 [1000/10853]\tLoss: 1.855667\tExact Match: 0.4365\tF1: 0.5643\n",
      "Train Epoch: 2 [2000/10853]\tLoss: 1.203987\tExact Match: 0.4442\tF1: 0.5720\n",
      "Train Epoch: 2 [3000/10853]\tLoss: 1.001253\tExact Match: 0.4492\tF1: 0.5789\n",
      "Train Epoch: 2 [4000/10853]\tLoss: 0.879528\tExact Match: 0.4513\tF1: 0.5819\n",
      "Train Epoch: 2 [5000/10853]\tLoss: 1.929977\tExact Match: 0.4546\tF1: 0.5864\n",
      "Train Epoch: 2 [6000/10853]\tLoss: 0.482206\tExact Match: 0.4564\tF1: 0.5881\n",
      "Train Epoch: 2 [7000/10853]\tLoss: 1.791981\tExact Match: 0.4601\tF1: 0.5914\n",
      "Train Epoch: 2 [8000/10853]\tLoss: 1.305593\tExact Match: 0.4616\tF1: 0.5935\n",
      "Train Epoch: 2 [9000/10853]\tLoss: 1.739060\tExact Match: 0.4637\tF1: 0.5959\n",
      "Train Epoch: 2 [10000/10853]\tLoss: 1.691767\tExact Match: 0.4667\tF1: 0.5993\n",
      "Val Epoch: 2 [1000/2538]\tLoss: 1.666115\tExact Match: 0.4838\tF1: 0.6209\n",
      "Val Epoch: 2 [2000/2538]\tLoss: 0.546647\tExact Match: 0.4844\tF1: 0.6223\n",
      "Epoch 2/3:\n",
      "Train Loss: 1.5512, Train Exact Match: 0.4691, Train F1: 0.6013\n",
      "Val Loss: 1.5700, Val Exact Match: 0.4848, Val F1: 0.6225\n",
      "Train Epoch: 3 [1000/10853]\tLoss: 1.796066\tExact Match: 0.5720\tF1: 0.7038\n",
      "Train Epoch: 3 [2000/10853]\tLoss: 1.278731\tExact Match: 0.5709\tF1: 0.7028\n",
      "Train Epoch: 3 [3000/10853]\tLoss: 2.366962\tExact Match: 0.5703\tF1: 0.7013\n",
      "Train Epoch: 3 [4000/10853]\tLoss: 1.677452\tExact Match: 0.5678\tF1: 0.6991\n",
      "Train Epoch: 3 [5000/10853]\tLoss: 1.192603\tExact Match: 0.5665\tF1: 0.6977\n",
      "Train Epoch: 3 [6000/10853]\tLoss: 2.664213\tExact Match: 0.5671\tF1: 0.6978\n",
      "Train Epoch: 3 [7000/10853]\tLoss: 0.783880\tExact Match: 0.5661\tF1: 0.6975\n",
      "Train Epoch: 3 [8000/10853]\tLoss: 1.090633\tExact Match: 0.5648\tF1: 0.6960\n",
      "Train Epoch: 3 [9000/10853]\tLoss: 0.812519\tExact Match: 0.5642\tF1: 0.6959\n",
      "Train Epoch: 3 [10000/10853]\tLoss: 1.039115\tExact Match: 0.5627\tF1: 0.6946\n",
      "Val Epoch: 3 [1000/2538]\tLoss: 0.717288\tExact Match: 0.5048\tF1: 0.6532\n",
      "Val Epoch: 3 [2000/2538]\tLoss: 2.611794\tExact Match: 0.5058\tF1: 0.6540\n",
      "Epoch 3/3:\n",
      "Train Loss: 1.2031, Train Exact Match: 0.5613, Train F1: 0.6938\n",
      "Val Loss: 1.5370, Val Exact Match: 0.5033, Val F1: 0.6513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 17:50:58,409] Trial 1 finished with value: 0.6144521919753582 and parameters: {'num_attention_heads': 4}. Best is trial 0 with value: 0.7356135293883699.\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/10853]\tLoss: 2.294487\tExact Match: 0.1199\tF1: 0.1911\n",
      "Train Epoch: 1 [2000/10853]\tLoss: 1.736404\tExact Match: 0.2360\tF1: 0.3371\n",
      "Train Epoch: 1 [3000/10853]\tLoss: 1.536915\tExact Match: 0.2967\tF1: 0.4091\n",
      "Train Epoch: 1 [4000/10853]\tLoss: 1.363695\tExact Match: 0.3342\tF1: 0.4519\n",
      "Train Epoch: 1 [5000/10853]\tLoss: 1.873098\tExact Match: 0.3624\tF1: 0.4844\n",
      "Train Epoch: 1 [6000/10853]\tLoss: 1.392168\tExact Match: 0.3812\tF1: 0.5073\n",
      "Train Epoch: 1 [7000/10853]\tLoss: 1.290132\tExact Match: 0.3975\tF1: 0.5259\n",
      "Train Epoch: 1 [8000/10853]\tLoss: 0.966064\tExact Match: 0.4111\tF1: 0.5413\n",
      "Train Epoch: 1 [9000/10853]\tLoss: 1.219522\tExact Match: 0.4227\tF1: 0.5537\n",
      "Train Epoch: 1 [10000/10853]\tLoss: 2.329051\tExact Match: 0.4340\tF1: 0.5653\n",
      "Val Epoch: 1 [1000/2538]\tLoss: 0.844888\tExact Match: 0.5331\tF1: 0.6815\n",
      "Val Epoch: 1 [2000/2538]\tLoss: 1.799387\tExact Match: 0.5350\tF1: 0.6810\n",
      "Epoch 1/3:\n",
      "Train Loss: 1.7170, Train Exact Match: 0.4407, Train F1: 0.5728\n",
      "Val Loss: 1.3889, Val Exact Match: 0.5306, Val F1: 0.6778\n",
      "Train Epoch: 2 [1000/10853]\tLoss: 1.805995\tExact Match: 0.5840\tF1: 0.7208\n",
      "Train Epoch: 2 [2000/10853]\tLoss: 1.746630\tExact Match: 0.5894\tF1: 0.7237\n",
      "Train Epoch: 2 [3000/10853]\tLoss: 1.059997\tExact Match: 0.5895\tF1: 0.7244\n",
      "Train Epoch: 2 [4000/10853]\tLoss: 0.623534\tExact Match: 0.5901\tF1: 0.7256\n",
      "Train Epoch: 2 [5000/10853]\tLoss: 0.944361\tExact Match: 0.5886\tF1: 0.7250\n",
      "Train Epoch: 2 [6000/10853]\tLoss: 1.511268\tExact Match: 0.5881\tF1: 0.7247\n",
      "Train Epoch: 2 [7000/10853]\tLoss: 1.337231\tExact Match: 0.5869\tF1: 0.7239\n",
      "Train Epoch: 2 [8000/10853]\tLoss: 1.628453\tExact Match: 0.5867\tF1: 0.7235\n",
      "Train Epoch: 2 [9000/10853]\tLoss: 2.021297\tExact Match: 0.5860\tF1: 0.7229\n",
      "Train Epoch: 2 [10000/10853]\tLoss: 0.737057\tExact Match: 0.5860\tF1: 0.7228\n",
      "Val Epoch: 2 [1000/2538]\tLoss: 1.107697\tExact Match: 0.5407\tF1: 0.6989\n",
      "Val Epoch: 2 [2000/2538]\tLoss: 1.224982\tExact Match: 0.5462\tF1: 0.6991\n",
      "Epoch 2/3:\n",
      "Train Loss: 1.1413, Train Exact Match: 0.5861, Train F1: 0.7227\n",
      "Val Loss: 1.3466, Val Exact Match: 0.5468, Val F1: 0.6991\n",
      "Train Epoch: 3 [1000/10853]\tLoss: 1.339966\tExact Match: 0.6755\tF1: 0.7976\n",
      "Train Epoch: 3 [2000/10853]\tLoss: 0.106183\tExact Match: 0.6721\tF1: 0.7943\n",
      "Train Epoch: 3 [3000/10853]\tLoss: 0.826596\tExact Match: 0.6669\tF1: 0.7915\n",
      "Train Epoch: 3 [4000/10853]\tLoss: 0.837422\tExact Match: 0.6615\tF1: 0.7883\n",
      "Train Epoch: 3 [5000/10853]\tLoss: 0.376365\tExact Match: 0.6595\tF1: 0.7863\n",
      "Train Epoch: 3 [6000/10853]\tLoss: 0.875881\tExact Match: 0.6576\tF1: 0.7848\n",
      "Train Epoch: 3 [7000/10853]\tLoss: 1.225258\tExact Match: 0.6567\tF1: 0.7833\n",
      "Train Epoch: 3 [8000/10853]\tLoss: 2.284849\tExact Match: 0.6538\tF1: 0.7812\n",
      "Train Epoch: 3 [9000/10853]\tLoss: 0.770874\tExact Match: 0.6524\tF1: 0.7800\n",
      "Train Epoch: 3 [10000/10853]\tLoss: 0.616253\tExact Match: 0.6512\tF1: 0.7792\n",
      "Val Epoch: 3 [1000/2538]\tLoss: 2.528728\tExact Match: 0.5489\tF1: 0.6943\n",
      "Val Epoch: 3 [2000/2538]\tLoss: 2.136066\tExact Match: 0.5463\tF1: 0.6938\n",
      "Epoch 3/3:\n",
      "Train Loss: 0.9179, Train Exact Match: 0.6504, Train F1: 0.7787\n",
      "Val Loss: 1.3947, Val Exact Match: 0.5465, Val F1: 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 18:23:43,904] Trial 2 finished with value: 0.6908553113090726 and parameters: {'num_attention_heads': 8}. Best is trial 0 with value: 0.7356135293883699.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of attention heads: 12\n",
      "Best F1 score: 0.7356135293883699\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import BertConfig, BertForQuestionAnswering\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space for the number of attention heads\n",
    "    num_attention_heads = trial.suggest_categorical('num_attention_heads', [4, 8, 12, 16])\n",
    "\n",
    "    # Load the pre-trained BERT model with the specified number of attention heads\n",
    "    config = BertConfig.from_pretrained('bert-base-cased', num_attention_heads=num_attention_heads,  hidden_size=768)\n",
    "    model = BertForQuestionAnswering.from_pretrained('bert-base-cased', config=config).to(device)\n",
    "    \n",
    "    from transformers import AdamW\n",
    "    optim = AdamW(model.parameters(), lr=5e-5)\n",
    "    model_save_path= '/home/sa.ekbote/cai6307-parsingpandas/num-heads/'\n",
    "\n",
    "    epochs = 3\n",
    "    # Train and evaluate the model (you can use your existing train_and_evaluate function)\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies =  train_and_evaluate(model, train_loader, val_loader, optim, epochs, model_save_path)\n",
    "\n",
    "\n",
    "    # Return the objective value (e.g., the average of the last few validation F1 scores)\n",
    "    return sum([f1 for _, f1 in val_accuracies[-3:]]) / 3 # Average of the last 3 epochs' F1 scores\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3)  # Adjust the number of trials as needed\n",
    "\n",
    "print(f\"Best number of attention heads: {study.best_params['num_attention_heads']}\")\n",
    "print(f\"Best F1 score: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd148474-65b4-489c-bebc-e764439ce4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 19:37:04,295] A new study created in memory with name: no-name-7ee526bc-21d7-4b60-88d1-080cd0b07944\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/10853]\tLoss: 1.999041\tExact Match: 0.2218\tF1: 0.3260\n",
      "Train Epoch: 1 [2000/10853]\tLoss: 1.864395\tExact Match: 0.3291\tF1: 0.4511\n",
      "Train Epoch: 1 [3000/10853]\tLoss: 1.904250\tExact Match: 0.3791\tF1: 0.5083\n",
      "Train Epoch: 1 [4000/10853]\tLoss: 1.082192\tExact Match: 0.4103\tF1: 0.5423\n",
      "Train Epoch: 1 [5000/10853]\tLoss: 1.356650\tExact Match: 0.4302\tF1: 0.5645\n",
      "Train Epoch: 1 [6000/10853]\tLoss: 1.188713\tExact Match: 0.4463\tF1: 0.5817\n",
      "Train Epoch: 1 [7000/10853]\tLoss: 2.124821\tExact Match: 0.4588\tF1: 0.5945\n",
      "Train Epoch: 1 [8000/10853]\tLoss: 0.816792\tExact Match: 0.4690\tF1: 0.6053\n",
      "Train Epoch: 1 [9000/10853]\tLoss: 2.339082\tExact Match: 0.4776\tF1: 0.6150\n",
      "Train Epoch: 1 [10000/10853]\tLoss: 1.866608\tExact Match: 0.4841\tF1: 0.6222\n",
      "Val Epoch: 1 [1000/2538]\tLoss: 2.622502\tExact Match: 0.5605\tF1: 0.7078\n",
      "Val Epoch: 1 [2000/2538]\tLoss: 0.884231\tExact Match: 0.5634\tF1: 0.7099\n",
      "Epoch 1/3:\n",
      "Train Loss: 1.5306, Train Exact Match: 0.4895, Train F1: 0.6280\n",
      "Val Loss: 1.2922, Val Exact Match: 0.5630, Val F1: 0.7099\n",
      "Train Epoch: 2 [1000/10853]\tLoss: 1.070126\tExact Match: 0.6425\tF1: 0.7734\n",
      "Train Epoch: 2 [2000/10853]\tLoss: 0.874874\tExact Match: 0.6388\tF1: 0.7693\n",
      "Train Epoch: 2 [3000/10853]\tLoss: 1.047264\tExact Match: 0.6396\tF1: 0.7692\n",
      "Train Epoch: 2 [4000/10853]\tLoss: 0.983492\tExact Match: 0.6382\tF1: 0.7686\n",
      "Train Epoch: 2 [5000/10853]\tLoss: 1.433523\tExact Match: 0.6358\tF1: 0.7670\n",
      "Train Epoch: 2 [6000/10853]\tLoss: 0.630567\tExact Match: 0.6336\tF1: 0.7653\n",
      "Train Epoch: 2 [7000/10853]\tLoss: 0.838791\tExact Match: 0.6328\tF1: 0.7649\n",
      "Train Epoch: 2 [8000/10853]\tLoss: 0.365131\tExact Match: 0.6319\tF1: 0.7639\n",
      "Train Epoch: 2 [9000/10853]\tLoss: 1.426920\tExact Match: 0.6302\tF1: 0.7628\n",
      "Train Epoch: 2 [10000/10853]\tLoss: 1.117319\tExact Match: 0.6289\tF1: 0.7623\n",
      "Val Epoch: 2 [1000/2538]\tLoss: 1.588818\tExact Match: 0.5737\tF1: 0.7166\n",
      "Val Epoch: 2 [2000/2538]\tLoss: 1.856476\tExact Match: 0.5740\tF1: 0.7172\n",
      "Epoch 2/3:\n",
      "Train Loss: 1.0123, Train Exact Match: 0.6288, Train F1: 0.7622\n",
      "Val Loss: 1.2803, Val Exact Match: 0.5713, Val F1: 0.7161\n",
      "Train Epoch: 3 [1000/10853]\tLoss: 0.598933\tExact Match: 0.7219\tF1: 0.8346\n",
      "Train Epoch: 3 [2000/10853]\tLoss: 1.111576\tExact Match: 0.7085\tF1: 0.8250\n",
      "Train Epoch: 3 [3000/10853]\tLoss: 0.505217\tExact Match: 0.7021\tF1: 0.8210\n",
      "Train Epoch: 3 [4000/10853]\tLoss: 0.793862\tExact Match: 0.6989\tF1: 0.8189\n",
      "Train Epoch: 3 [5000/10853]\tLoss: 0.762871\tExact Match: 0.6973\tF1: 0.8181\n",
      "Train Epoch: 3 [6000/10853]\tLoss: 0.674130\tExact Match: 0.6960\tF1: 0.8165\n",
      "Train Epoch: 3 [7000/10853]\tLoss: 0.320991\tExact Match: 0.6942\tF1: 0.8154\n",
      "Train Epoch: 3 [8000/10853]\tLoss: 1.723526\tExact Match: 0.6942\tF1: 0.8157\n",
      "Train Epoch: 3 [9000/10853]\tLoss: 0.621790\tExact Match: 0.6920\tF1: 0.8141\n",
      "Train Epoch: 3 [10000/10853]\tLoss: 1.312094\tExact Match: 0.6896\tF1: 0.8127\n",
      "Val Epoch: 3 [1000/2538]\tLoss: 0.729730\tExact Match: 0.5705\tF1: 0.7200\n",
      "Val Epoch: 3 [2000/2538]\tLoss: 1.566704\tExact Match: 0.5722\tF1: 0.7203\n",
      "Epoch 3/3:\n",
      "Train Loss: 0.8003, Train Exact Match: 0.6889, Train F1: 0.8122\n",
      "Val Loss: 1.3705, Val Exact Match: 0.5707, Val F1: 0.7194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 20:24:51,561] Trial 0 finished with value: 0.7151476955284962 and parameters: {'num_attention_heads': 24}. Best is trial 0 with value: 0.7151476955284962.\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/10853]\tLoss: 1.076508\tExact Match: 0.1794\tF1: 0.2673\n",
      "Train Epoch: 1 [2000/10853]\tLoss: 2.460409\tExact Match: 0.2921\tF1: 0.4046\n",
      "Train Epoch: 1 [3000/10853]\tLoss: 1.917639\tExact Match: 0.3519\tF1: 0.4738\n",
      "Train Epoch: 1 [4000/10853]\tLoss: 1.332964\tExact Match: 0.3869\tF1: 0.5144\n",
      "Train Epoch: 1 [5000/10853]\tLoss: 1.482956\tExact Match: 0.4092\tF1: 0.5393\n",
      "Train Epoch: 1 [6000/10853]\tLoss: 1.205837\tExact Match: 0.4271\tF1: 0.5599\n",
      "Train Epoch: 1 [7000/10853]\tLoss: 1.177798\tExact Match: 0.4417\tF1: 0.5756\n",
      "Train Epoch: 1 [8000/10853]\tLoss: 1.135452\tExact Match: 0.4528\tF1: 0.5886\n",
      "Train Epoch: 1 [9000/10853]\tLoss: 2.120407\tExact Match: 0.4618\tF1: 0.5990\n",
      "Train Epoch: 1 [10000/10853]\tLoss: 1.558370\tExact Match: 0.4708\tF1: 0.6079\n",
      "Val Epoch: 1 [1000/2538]\tLoss: 1.873512\tExact Match: 0.5603\tF1: 0.7075\n",
      "Val Epoch: 1 [2000/2538]\tLoss: 1.798788\tExact Match: 0.5586\tF1: 0.7047\n",
      "Epoch 1/3:\n",
      "Train Loss: 1.5830, Train Exact Match: 0.4775, Train F1: 0.6151\n",
      "Val Loss: 1.2784, Val Exact Match: 0.5601, Val F1: 0.7072\n",
      "Train Epoch: 2 [1000/10853]\tLoss: 1.451923\tExact Match: 0.6286\tF1: 0.7601\n",
      "Train Epoch: 2 [2000/10853]\tLoss: 0.854175\tExact Match: 0.6296\tF1: 0.7636\n",
      "Train Epoch: 2 [3000/10853]\tLoss: 1.329453\tExact Match: 0.6273\tF1: 0.7616\n",
      "Train Epoch: 2 [4000/10853]\tLoss: 1.036568\tExact Match: 0.6266\tF1: 0.7601\n",
      "Train Epoch: 2 [5000/10853]\tLoss: 0.657002\tExact Match: 0.6240\tF1: 0.7575\n",
      "Train Epoch: 2 [6000/10853]\tLoss: 0.699977\tExact Match: 0.6229\tF1: 0.7562\n",
      "Train Epoch: 2 [7000/10853]\tLoss: 1.016356\tExact Match: 0.6205\tF1: 0.7541\n",
      "Train Epoch: 2 [8000/10853]\tLoss: 0.735725\tExact Match: 0.6185\tF1: 0.7525\n",
      "Train Epoch: 2 [9000/10853]\tLoss: 1.153363\tExact Match: 0.6184\tF1: 0.7526\n",
      "Train Epoch: 2 [10000/10853]\tLoss: 0.503420\tExact Match: 0.6179\tF1: 0.7521\n",
      "Val Epoch: 2 [1000/2538]\tLoss: 0.737269\tExact Match: 0.5749\tF1: 0.7193\n",
      "Val Epoch: 2 [2000/2538]\tLoss: 0.709124\tExact Match: 0.5763\tF1: 0.7206\n",
      "Epoch 2/3:\n",
      "Train Loss: 1.0464, Train Exact Match: 0.6184, Train F1: 0.7526\n",
      "Val Loss: 1.2831, Val Exact Match: 0.5734, Val F1: 0.7198\n",
      "Train Epoch: 3 [1000/10853]\tLoss: 1.088046\tExact Match: 0.7020\tF1: 0.8217\n",
      "Train Epoch: 3 [2000/10853]\tLoss: 0.404770\tExact Match: 0.6981\tF1: 0.8189\n",
      "Train Epoch: 3 [3000/10853]\tLoss: 0.979815\tExact Match: 0.6935\tF1: 0.8137\n",
      "Train Epoch: 3 [4000/10853]\tLoss: 0.614264\tExact Match: 0.6895\tF1: 0.8105\n",
      "Train Epoch: 3 [5000/10853]\tLoss: 0.148686\tExact Match: 0.6870\tF1: 0.8091\n",
      "Train Epoch: 3 [6000/10853]\tLoss: 0.517318\tExact Match: 0.6832\tF1: 0.8073\n",
      "Train Epoch: 3 [7000/10853]\tLoss: 1.014038\tExact Match: 0.6805\tF1: 0.8054\n",
      "Train Epoch: 3 [8000/10853]\tLoss: 0.400884\tExact Match: 0.6789\tF1: 0.8038\n",
      "Train Epoch: 3 [9000/10853]\tLoss: 0.931621\tExact Match: 0.6776\tF1: 0.8028\n",
      "Train Epoch: 3 [10000/10853]\tLoss: 0.644594\tExact Match: 0.6770\tF1: 0.8024\n",
      "Val Epoch: 3 [1000/2538]\tLoss: 0.954103\tExact Match: 0.5639\tF1: 0.7131\n",
      "Val Epoch: 3 [2000/2538]\tLoss: 0.712339\tExact Match: 0.5647\tF1: 0.7117\n",
      "Epoch 3/3:\n",
      "Train Loss: 0.8392, Train Exact Match: 0.6758, Train F1: 0.8013\n",
      "Val Loss: 1.3342, Val Exact Match: 0.5671, Val F1: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 21:05:44,969] Trial 1 finished with value: 0.7132777331456029 and parameters: {'num_attention_heads': 16}. Best is trial 0 with value: 0.7151476955284962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of attention heads: 24\n",
      "Best F1 score: 0.7151476955284962\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import BertConfig, BertForQuestionAnswering\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space for the number of attention heads\n",
    "    num_attention_heads = trial.suggest_categorical('num_attention_heads', [16,24])\n",
    "\n",
    "    # Load the pre-trained BERT model with the specified number of attention heads\n",
    "    config = BertConfig.from_pretrained('bert-base-cased', num_attention_heads=num_attention_heads,  hidden_size=768)\n",
    "    model = BertForQuestionAnswering.from_pretrained('bert-base-cased', config=config).to(device)\n",
    "    \n",
    "    from transformers import AdamW\n",
    "    optim = AdamW(model.parameters(), lr=5e-5)\n",
    "    model_save_path= '/home/sa.ekbote/cai6307-parsingpandas/num-heads/'\n",
    "\n",
    "    epochs = 3\n",
    "    # Train and evaluate the model (you can use your existing train_and_evaluate function)\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies =  train_and_evaluate(model, train_loader, val_loader, optim, epochs, model_save_path)\n",
    "\n",
    "\n",
    "    # Return the objective value (e.g., the average of the last few validation F1 scores)\n",
    "    return sum([f1 for _, f1 in val_accuracies[-3:]]) / 3 # Average of the last 3 epochs' F1 scores\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=2)  # Adjust the number of trials as needed\n",
    "\n",
    "print(f\"Best number of attention heads: {study.best_params['num_attention_heads']}\")\n",
    "print(f\"Best F1 score: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ab7068-f38d-42c9-9e75-b75da57aed9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('/home/sa.ekbote/cai6307-parsingpandas/models/bert-base-cased',map_location=torch.device('cuda'))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed526517-6ea3-4532-85a9-ea9397a1e3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_on_unanswerable_questions(model, val_loader, optimizer, epochs, model_save_path):\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "\n",
    "        print_every = 1000  # Print every 500 steps\n",
    "        scaler = GradScaler()  # Initialize the gradient scaler for mixed precision training\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_exact_match = 0\n",
    "        total_val_f1 = 0\n",
    "        total_val_examples = 0\n",
    "        print_every=1000\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, batch in enumerate(val_loader):\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    start_positions = batch['start_positions'].to(device)\n",
    "                    end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "                    with autocast():  # Enable automatic mixed precision for evaluation\n",
    "                        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "                        loss = outputs.loss\n",
    "\n",
    "                    total_val_loss += loss.item()\n",
    "\n",
    "                    # Convert logits to answer spans (this part is not affected by mixed precision)\n",
    "                    start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "                    start_predictions = torch.argmax(start_logits, dim=-1)\n",
    "                    end_predictions = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "                    for i in range(input_ids.size(0)):\n",
    "                        start_pred = start_predictions[i].item()\n",
    "                        end_pred = end_predictions[i].item()\n",
    "                        predicted_answer = tokenizer.decode(input_ids[i, start_pred:end_pred + 1])\n",
    "\n",
    "                        ground_truth_answer = tokenizer.decode(input_ids[i, start_positions[i]:end_positions[i] + 1])\n",
    "\n",
    "                        total_val_exact_match += exact_match_score(predicted_answer, ground_truth_answer)\n",
    "                        total_val_f1 += f1_score(predicted_answer, ground_truth_answer)\n",
    "                        total_val_examples += 1\n",
    "\n",
    "                    if (batch_idx + 1) % print_every == 0:\n",
    "                        print(f\"Val Epoch: {epoch + 1} [{batch_idx + 1}/{len(val_loader)}]\\tLoss: {loss.item():.6f}\\tExact Match: {total_val_exact_match / total_val_examples:.4f}\\tF1: {total_val_f1 / total_val_examples:.4f}\")\n",
    "\n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            avg_val_exact_match = total_val_exact_match / total_val_examples\n",
    "            avg_val_f1 = total_val_f1 / total_val_examples\n",
    "\n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_accuracies.append((avg_val_exact_match, avg_val_f1))\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{epochs}:')\n",
    "            print(f'Val Loss: {avg_val_loss:.4f}, Val Exact Match: {avg_val_exact_match:.4f}, Val F1: {avg_val_f1:.4f}')\n",
    "\n",
    "            # Save the model after each epoch\n",
    "            torch.save(model.state_dict(), f\"{model_save_path}/model_epoch_unanswerable{epoch + 1}.pth\")\n",
    "\n",
    "        return val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28e98aca-6a91-4311-800b-a6d8b48cb96c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5945\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Assuming you have the SQuAD v2.0 dataset in a JSON file\n",
    "squad_v2_file = 'squad/dev-v2.0.json'\n",
    "with open(squad_v2_file, 'r') as reader:\n",
    "    squad_dict = json.load(reader)\n",
    "\n",
    "# Prepare the dataset\n",
    "class SQuADUnanswerableDataset(Dataset):\n",
    "    def __init__(self, entries, tokenizer, max_length):\n",
    "        self.entries = entries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        question = entry['question']\n",
    "        context = entry['context']\n",
    "        encoding = self.tokenizer.encode_plus(question, context, \n",
    "                                              add_special_tokens=True,\n",
    "                                              max_length=self.max_length, \n",
    "                                              truncation=True, padding='max_length',\n",
    "                                              return_attention_mask=True, \n",
    "                                              return_tensors='pt',\n",
    "                                              truncation_strategy='longest_first'\n",
    "                    )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'start_positions': torch.tensor(0),  # Unanswerable questions have start_positions at 0\n",
    "            'end_positions': torch.tensor(0)  # Unanswerable questions have end_positions at 0\n",
    "        }\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "max_length = 512  # or the max length you're using for your model\n",
    "\n",
    "# Extract unanswerable questions\n",
    "unanswerable_entries = []\n",
    "for article in squad_dict['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            if qa['is_impossible']:\n",
    "                unanswerable_entries.append({\n",
    "                    'context': context,\n",
    "                    'question': qa['question']\n",
    "                })\n",
    "\n",
    "# Create a dataset and loader for unanswerable questions\n",
    "print(len(unanswerable_entries))\n",
    "# Create a dataset and loader for unanswerable questions\n",
    "unanswerable_dataset = SQuADUnanswerableDataset(unanswerable_entries, tokenizer, max_length)\n",
    "unanswerable_loader = DataLoader(unanswerable_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Now you can iterate over unanswerable_loader in your evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe0af5af-6a3c-462c-8942-3484e0f5a5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5945\n"
     ]
    }
   ],
   "source": [
    "print(len(unanswerable_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4f5b132f-df39-4604-877a-66c35fd729a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "Val Loss: 6.2111, Val Exact Match: 0.0000, Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "Val Loss: 12.4222, Val Exact Match: 0.0000, Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "Val Loss: 18.6332, Val Exact Match: 0.0000, Val F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"/home/sa.ekbote/cai6307-parsingpandas/bert_squad_v2/\"\n",
    "val_losses, val_accuracies = validate_on_unanswerable_questions(model, unanswerable_loader, optim, epochs, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7f61b99-6fa1-465b-98db-f1329104897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5945\n",
      "Accuracy on unanswerable questions: 0.69\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_on_unanswerable_questions(model, dataloader, device):\n",
    "    \n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_unanswerable = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            \n",
    "            # If the start and end positions are both zero, we might assume it's unanswerable.\n",
    "            actual_no_answer = (start_positions == 0) & (end_positions == 0)\n",
    "            #print(actual_no_answer)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "            \n",
    "            # Get the highest probability for start and end being at the same position\n",
    "            start_probs = torch.softmax(start_logits, dim=-1)\n",
    "            end_probs = torch.softmax(end_logits, dim=-1)\n",
    "            \n",
    "            # Get the probability of 'no answer' (i.e., start and end at [CLS] token)\n",
    "            no_answer_probs = start_probs[:, 0] * end_probs[:, 0]\n",
    "            #print(no_answer_probs)\n",
    "\n",
    "            # Predict 'no answer' if the model is sufficiently confident\n",
    "            # Here we broadcast the comparison for each element in the NumPy array\n",
    "            preds_no_answer = no_answer_probs > no_answer_threshold\n",
    "            #print(preds_no_answer)\n",
    "            preds_no_answer = preds_no_answer.cpu().numpy()  # Move predictions to CPU for comparison with NumPy array\n",
    "\n",
    "            # Count correct predictions (both numpy arrays now, so we can directly compare)\n",
    "            correct_predictions += np.sum((preds_no_answer == actual_no_answer.cpu().numpy()) & actual_no_answer.cpu().numpy())\n",
    "            total_unanswerable += actual_no_answer.sum().item()\n",
    "    \n",
    "    print(total_unanswerable)\n",
    "\n",
    "    accuracy = correct_predictions / total_unanswerable if total_unanswerable > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Define the threshold for predicting 'no answer'\n",
    "no_answer_threshold = 0.45  # Starting threshold  # This may need to be tuned for your model and data\n",
    "\n",
    "# Assuming you have a valid val_loader set up\n",
    "accuracy = evaluate_on_unanswerable_questions(model, unanswerable_loader, device)\n",
    "print(f\"Accuracy on unanswerable questions: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8ef3206-60ed-4807-a346-aa8f958af0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: The agreements include fixed annual carriage fees of £30m for the channels with both channel suppliers able to secure additional capped payments if their channels meet certain performance-related targets. Currently there is no indication as to whether the new deal includes the additional Video On Demand and High Definition content which had previously been offered by BSkyB. As part of the agreements, both BSkyB and Virgin Media agreed to terminate all High Court proceedings against each other relating to the carriage of their respective basic channels.\n",
      "Question: What were the weekly carriage fees for the channels?\n",
      "\n",
      "\n",
      "Context: New techniques of building construction are being researched, made possible by advances in 3D printing technology. In a form of additive building construction, similar to the additive manufacturing techniques for manufactured parts, building printing is making it possible to flexibly construct small commercial buildings and private habitations in around 20 hours, with built-in plumbing and electrical facilities, in one continuous build, using large 3D printers. Working versions of 3D-printing building technology are already printing 2 metres (6 ft 7 in) of building material per hour as of January 2013[update], with the next-generation printers capable of 3.5 metres (11 ft) per hour, sufficient to complete a building in a week. Dutch architect Janjaap Ruijssenaars's performative architecture 3D-printed building is scheduled to be built in 2014.\n",
      "Question: What is Janjaap Ruijssenaar going to build in 2013?\n",
      "\n",
      "\n",
      "Context: In the mid-1950s, Frank Burnet, inspired by a suggestion made by Niels Jerne, formulated the clonal selection theory (CST) of immunity. On the basis of CST, Burnet developed a theory of how an immune response is triggered according to the self/nonself distinction: \"self\" constituents (constituents of the body) do not trigger destructive immune responses, while \"nonself\" entities (pathogens, an allograft) trigger a destructive immune response. The theory was later modified to reflect new discoveries regarding histocompatibility or the complex \"two-signal\" activation of T cells. The self/nonself theory of immunity and the self/nonself vocabulary have been criticized, but remain very influential.\n",
      "Question: What theory did Niels Jerne formulate?\n",
      "\n",
      "\n",
      "Context: In February 2010, in response to controversies regarding claims in the Fourth Assessment Report, five climate scientists – all contributing or lead IPCC report authors – wrote in the journal Nature calling for changes to the IPCC. They suggested a range of new organizational options, from tightening the selection of lead authors and contributors, to dumping it in favor of a small permanent body, or even turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC. Other recommendations included that the panel employ a full-time staff and remove government oversight from its processes to avoid political interference.\n",
      "Question: What date was the Fourth Assessment Report published?\n",
      "\n",
      "\n",
      "Context: Hamas has continued to be a major player in Palestine. From 2000 to 2007 it killed 542 people in 140 suicide bombing or \"martyrdom operations\". In the January 2006 legislative election—its first foray into the political process—it won the majority of the seats, and in 2007 it drove the PLO out of Gaza. Hamas has been praised by Muslims for driving Israel out of the Gaza Strip, but criticized for failure to achieve its demands in the 2008-9 and 2014 Gaza Wars despite heavy destruction and significant loss of life.\n",
      "Question: What organization has stopped being a major disruptive force in Palestine?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Load SQuAD dataset from a JSON file\n",
    "def load_squad_data(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        squad_data = json.load(file)\n",
    "    return squad_data\n",
    "\n",
    "# Extract multiple unanswerable questions and their contexts\n",
    "def get_unanswerable_questions(squad_data, num_questions=5):\n",
    "    unanswerable_entries = []\n",
    "    for article in squad_data['data']:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                if qa['is_impossible']:\n",
    "                    unanswerable_entries.append({\n",
    "                        'context': context,\n",
    "                        'question': qa['question']\n",
    "                    })\n",
    "                    # Early stop if we collected enough entries\n",
    "                    if len(unanswerable_entries) >= num_questions * 10:  # Collect more to randomize\n",
    "                        break\n",
    "\n",
    "    # Randomly select 'num_questions' entries\n",
    "    if len(unanswerable_entries) > num_questions:\n",
    "        return random.sample(unanswerable_entries, num_questions)\n",
    "    else:\n",
    "        return unanswerable_entries  # Return all if less than requested\n",
    "\n",
    "# Specify the path to your SQuAD v2.0 dataset JSON file\n",
    "json_file_path = 'squad/dev-v2.0.json'\n",
    "\n",
    "# Load the data\n",
    "squad_data = load_squad_data(json_file_path)\n",
    "\n",
    "# Get five random unanswerable questions\n",
    "unanswerable_questions = get_unanswerable_questions(squad_data, num_questions=5)\n",
    "\n",
    "# Display the questions\n",
    "for entry in unanswerable_questions:\n",
    "    print(\"Context:\", entry['context'])\n",
    "    print(\"Question:\", entry['question'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a5beea8-41fa-4b14-970d-19a96e6e2a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is the capital of india\n",
      "Prediction: india [SEP] capital of india\n",
      "True Answer: new-delhi\n",
      "EM: 0\n",
      "F1: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"capital of india is new-delhi\"\"\"\n",
    "\n",
    "queries = [\n",
    "           \"what is the capital of india\"\n",
    "          ]\n",
    "answers = [\n",
    "           \"new-delhi\"\n",
    "          ]\n",
    "\n",
    "for q,a in zip(queries,answers):\n",
    "      give_an_answer(context,q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eacff5-9603-49e0-a26f-d5e9a808a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\" In February 2010, in response to controversies regarding claims in the Fourth Assessment Report, five climate scientists – all contributing or lead IPCC report authors – wrote in the journal Nature calling for changes to the IPCC. They suggested a range of new organizational options, from tightening the selection of lead authors and contributors, to dumping it in favor of a small permanent body, or even turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC. Other recommendations included that the panel employ a full-time staff and remove government oversight from its processes to avoid political interference. \"\"\"\n",
    "\n",
    "queries = [\n",
    "           \"What date was the Fourth Assessment Report published?\"\n",
    "          ]\n",
    "answers = [\n",
    "           \"\"\n",
    "          ]\n",
    "\n",
    "for q,a in zip(queries,answers):\n",
    "      give_an_answer(context,q,a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UFRC Python-3.10",
   "language": "python",
   "name": "python3-3.10-ufrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
